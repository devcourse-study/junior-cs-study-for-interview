## Process & Thread

<details>
    <summary><b>Process 개념</b></summary>

### Process란?
실행중인 프로그램을 의미합니다. 디스크에 있는 실행 파일이 메모리에 올라가 CPU의 할당을 받을 수 있게 됩니다.  
프로세스는 독립적인 메모리를 할당받기 때문에, 다른 프로세스에 접근할 수 없습니다.

### Process 구성 요소
- Code 영역 : 실행할 프로그램의 명령어들이 위치하는 공간입니다.
- Data 영역 : 전역변수와 static 변수들이 위치하는 공간입니다.
- Heap 영역 : 동적으로 할당되는 데이터를 저장하는 공간입니다.
- Stack 영역 : 함수 호출에 사용되는 데이터가 위치하는 공간입니다.

### 프로세스의 상태
- new: 프로세스가 생성된 상태
- ready: CPU의 할당을 받아 running 상태가 될 준비가 완료된 상태
- running: CPU에 의해 실행되고 있는 상태
- waiting: I/O 등의 작업이 발생하길 기다리는 상태
- terminated: 프로세스가 종료된 상태

</details>

<details>
    <summary><b>Multi Process</b></summary>

### 멀티 프로세스란?
멀티 프로세스란 여러 프로세스가 협력하여 하나의 프로그램을 병렬처리하는 것을 의미합니다.  
혹은, 독립된 프로세스들이 컨텍스트 스위칭을 통해 번갈아 가며 실행되는 과정을 의미합니다.

</details>

<details>
    <summary><b>PCB(Process Control Block)</b></summary>

### PCB란?
PCB는 운영체제가 프로세스를 제어하기 위해 프로세스의 상태를 저장하는 것입니다.  
프로세스의 상태관리와 context switching을 하기 위해 필요합니다.  
프로세스가 생성 시 만들어지며 메모리에 할당됩니다.  
컨텍스트 스위칭을 위해 PCB가 사용되고, 실제 스케쥴링 시에는 PCB의 메모리 주소를 통해 스케쥴링됩니다.

### PCB 구성 요소
- PID: 프로세스 번호
- 상태: 준비, 대기, 실행 등의 상태
- Register save area: 레지스터 관련 정보
  - Program counter: 다음 실행될 명령어의 포인터
  - Stack pointer의 위치 
- Priority: 스케쥴링 우선순위
- 프로세스가 위치한 메모리 포인터
- 할당된 자원 정보
- Account: CPU 사용 시간
- I/O관련 정보
</details>

<details>
    <summary><b>Context, Context Switch</b></summary>

### Context Switch란?
Context Switch란 CPU가 실행할 프로세스 혹은 쓰레드를 교체하는 작업을 의미합니다.  
CPU가 처리할 프로세스를 교체하기 위해선 CPU가 해당 프로세스에 대한 정보를 임시로 저장해야 하는데, 이 정보를 컨텍스트라고 합니다.  
컨텍스트 스위칭을 하게 되면, 하나의 프로세스의 전체 실행동안 계속 선점하는 것에 비해 CPU를 더 효율적으로 사용할 수 있습니다.  
예를 들어, 한 프로세스가 I/O이 끝날때까지 CPU도 선점하고 있다면, 이 동안 CPU는 idle 상태가 됩니다.  
이렇게 CPU가 쉬는 시간을 활용하기 위해 컨텍스트 스위칭을 통해 다른 프로세스를 실행할 수 있게 됩니다.

### Context Switch 과정
1. 기존에 CPU에 의해 실행중이던 프로세스가 교체될 상황에 놓입니다.
   - 프로세스 최대 실행시간에 도달한 경우
   - I/O 작업이 필요한 경우
   - 인터럽트가 발생한 경우
2. 기존 프로세스에 대한 실행 정보를 PCB에 저장합니다.
3. 새로 실행될 프로세스에 대한 PCB를 통해 프로세스를 교체 실행합니다.

</details>

<details>
    <summary><b>Thread 개념</b></summary>

### 쓰레드란?
쓰레드란 프로세스 내에서 실행되는 작업의 단위를 의미합니다.  
한 프로세스 내에는 여러 쓰레드가 있을 수 있고, 프로세스의 Code, Data, Heap 영역을 공유합니다.

</details>

<details>
    <summary><b>Multi Thread</b></summary>

### 멀티 쓰레드의 장단점
- 장점
  - 멀티 프로세스에 비해 컨텍스트 스위칭 오버헤드가 더 가볍습니다. CPU가 사용했던 데이터를 캐싱하고 조회하는 것이 더 효율적이기 때문입니다.
  - 쓰레드는 프로세스 내 메모리 영역을 공유하기 때문에 쓰레드 간 통신이 간단합니다.
- 단점
  - 메모리 영역을 공유하기 때문에 쓰레드 간 동기화 문제가 발생할 수 있습니다.
  - 한 쓰레드가 비정상적으로 종료되면, 전체 프로세스에 영향이 갈 수 있습니다.
</details>

<details>
    <summary><b>IPC(Inter Process Communication)</b></summary>

### IPC란?
IPC는 프로세스 간에 데이터를 주고받는 방법입니다.  
프로세스는 다른 프로세스로부터 독립적인 메모리 공간을 받기 때문에, 여러 프로세스가 데이터를 주고받으며 병렬적으로 작업을 처리하려면 별도의 데이터 통신이 필요합니다.  
이를 해결하기 위해 IPC가 제공됩니다.

</details>

<details>
    <summary><b>공유 메모리와 메시지 전달 모델</b></summary>

1. 공유 메모리: 프로세스에 메모리 공간의 일부를 공유하여, 공유한 메모리 영역에 I/O 작업을 하며 데이터를 통신하는 방식입니다.
   - 장점: 커널(운영체제의 핵심 기능)이 관여하지 않고 메모리 영역을 공유하기 때문에 속도가 빠릅니다.
   - 단점: 데이터를 전달하는 방식이 아니기 때문에, 메모리에 데이터를 읽어야 하는 시점을 알 수 없고, 별도의 기술이 필요합니다.
2. 메세지 전달: 커널 메모리 영역에 메세지 전달을 위한 채널을 만들어서 프로세스 사이의 데이터를 송수신 하는 방법입니다.
   - 장점: 커널이 메세지 전달을 관리하기 때문에, 프로그램 차원에서의 별도의 로직이 필요하지 않습니다.
   - 단점: 커널을 통해서 메세지를 전달하기 때문에, 공유 메모리 방식에 비해 느립니다.
   - 파이프 방식: 부모-자식 프로세스 간의 단방향 메세지 통신입니다.
   - 큐 방식: 큐 자료구조를 활용하여 양방향 메세지 통신이 가능합니다. 부모-자식 관계가 아니어도 통신할 수 있습니다.
   - 소켓: 네트워크 통신 방식인 소켓을 이용하여, 프로세스의 포트번호를 정하고, 해당 포트 간의 데이터 통신을 진행합니다.
</details>

<details>
    <summary><b>Multi Process/Thread 환경의 동기화 문제해결. Mutex, Semaphore</b></summary>

### 동기화 문제
동시에 여러 프로세스가 공유 데이터에 접근하려 할 때, 접근 순서에 따라서 결과가 달라지는 Race Condition이 발생합니다.  
이를 해결하기 위해 동기화(Synchronization)이 필요합니다.

### Synchronization
동기화를 위해서는 critical section에 대해 상호 접근 배제를 보장해야 합니다. 

### Critical Section
critical section은 공유 데이터에 접근해서 값을 바꾸는 코드를 의미합니다.
critical section에 대해 동기화를 하지 않았을 때 발생하는 문제를 해결하기 위해서는 조건들을 만족해야 합니다.
- Mutual Exclusion(상호 배제): 이미 한 프로세스가 critical section에 접근중이라면 다른 프로세스는 접근하면 안됩니다.
- Progress(진행): 아무런 프로세스도 접근하지 않았다면 critical section에 접근할 수 있어야 합니다.
- Bounded Waiting(한정 대기): critical section에 접근하기 위해 무한정 기다리면 안됩니다.

### Mutex
Mutex는 공유자원에 하나의 프로세스만 접근할 수 있는 동기화 방식입니다.  
공유 자원에 이미 다른 프로세스가 접근중이라면 lock을 얻기 위해 대기합니다.  
접근할 수 있다면 lock을 획득하며 공유 자원에 접근하고, 실행이 완료되면 lock을 반환하며 다른 프로세스가 접근할 수 있도록 합니다.  

### Semaphore
Semaphore는 여러 프로세스가 공유 자원에 접근할 수 있고, busy waiting이 필요 없는 동기화 방식입니다.  
Semaphore는 공유 자원의 개수를 나타내는 카운터(counter)로 동기화를 관리합니다.  
공유 자원에 접근할 수 있으면 카운터--를 하고, 사용이 완료되면 카운터++을 합니다.  
그리고 while문을 사용할 때의 busy waiting을 피하기 위해 Block & Wakeup 방식을 사용합니다.  
critical section으로의 진입에 실패하면 기다리지 않고 waiting queue에 가고, wake up이 발생하면 waiting queue에 있던 프로세스들이 모두 ready queue로 이동합니다.
- 카운터가 음수일 때: 이미 모든 자원들이 사용중이고, 프로세스들이 대기중입니다.
- 카운터가 0 이상일 때: 공유 자원에 적어도 하나의 프로세스가 접근할 수 있습니다.

### Binary Semaphore는 Mutex인가요?
Mutex는 자원을 선점 프로세스만 락을 반납할 수 있지만, Semaphore는 자원을 선점하지 않은 프로세스도 락을 반납할 수 있기 때문에, 둘은 다른 개념입니다.

</details>

<details>
    <summary><b>Deadlock</b></summary>

### 데드락이란?
데드락은 여러 프로세스가 한정된 자원을 얻고자 무한히 기다리는 상황을 말합니다.  
자원 A를 선점한 프로세스가 자원 B를 선점한 프로세스의 B를 얻기 위해 기다리고, 자원 B를 선점한 프로세스가 A를 얻고자 기다린다면 이는 데드락에 해당됩니다.

### 데드락이 걸리기 위한 조건
1. 상호 배제: 매 순간 하나의 프로세스만이 자원을 사용할 수 있습니다.
2. 보유 대기: 자원을 선점한 프로세스가 다른 자원을 기다릴 때, 선점한 자원을 놓지 않고 계속 갖고 있습니다.
3. 비선점: 프로세스는 OS에 의해 강제로 자원을 뺏기지 않습니다.
4. 순환 대기: 자원을 기다리는 프로세스 간 사이클이 형성되어야 합니다.

### 데드락 해결 방법
1. 데드락 예방: 데드락이 일어나지 않도록 미리 방지하는 방식입니다. 하지만 이 방식은 시스템의 처리 속도 및 효율성을 떨어뜨린다는 단점이 있습니다.
2. 데드락 회피: 데드락이 발생할 수 있는 경우에는 자원을 할당하지 않도록 알고리즘으로 회피하는 방식입니다. 하지만 이 방식은 프로세스마다 최대 자원 요구량을 알아야 하고, 기타 제약조건이 많습니다.
3. 데드락 탐지 및 회복: 데드락 회피 기법과 비슷한 방식으로 데드락이 발생하는지 탐지한 후, 프로세스를 중단하거나 자원을 선점하는 방식으로 데드락을 회복합니다.
4. 데드락 무시: 데드락이 일어나지 않는다고 가정하고, 일어날 경우에는 사용자가 직접 프로세스를 죽이는 방식입니다. 이는 실제로 데드락이 일어날 조건이 매우 까다롭기 때문에, 대부분의 운영체제에서 사용됩니다.
</details>

---

## Memory

<details>
    <summary><b>Paging</b></summary>

### Paging이란?
Paging이란 논리주소의 메모리를 고정된 크기의 Page로 나누어 관리하는 방법입니다.  
페이지 테이블을 이용해 논리주소와 매핑되는 물리주소를 반환하는 식으로 메모리를 할당합니다.  

- 논리 주소: 사용자 프로세스에만 의미있는 주소
- 물리 주소: 실제 메모리에 할당되는 주소

### Paging의 특징
- 물리 주소 공간을 페이지와 같은 사이즈로 나눈 프레임(Frame) 단위로 관리합니다.
- 물리 주소 공간은 연속적이지 않을 수 있습니다.
- 외부 단편화는 발생하지 않지만, 내부 단편화는 발생할 수 있습니다. 페이지의 크기와 프레임의 크기가 똑같기 때문에, 모든 프로세스의 메모리를 페이지 단위로 프레임에 할당받을 수 있습니다.
  - 외부 단편화: 물리 주소 공간에 메모리가 파편화되어있어서, 파편들의 합은 충분히 커서 메모리를 할당할 수 있지만 실제로 주소 공간이 나뉘어있기 때문에 프로세스가 메모리를 할당받지 못하는 현상
  - 내부 단편화: 남아있는 메모리 공간이 할당받아야 하는 메모리 공간보다 더 크기 때문에, 할당 받은 이후에 사용되지 않는 메모리 공간이 남는 현상
- 페이징으로 인해 메모리를 보호할 수 있고, 페이지를 공유할 수 있습니다.

### Page Table
페이지 테이블이란 논리 주소와 매핑되는 물리 주소 정보를 갖고 있는 테이블을 의미합니다.
- 프로세스마다 페이지 테이블을 갖습니다.
- Page Table Base Register(페이지 테이블을 가리키는 레지스터), Page Table Length Register(페이지 테이블 크기를 가리키는 레지스터) 정보가 PCB에 저장됩니다.
- 페이지 테이블의 존재 때문에, 실제 물리 주소에 접근하기 위해서는 페이지 테이블에 한번, 실제 물리 주소에 두번의 메모리 주소 접근이 필요합니다.

### Paging을 쓰는 이유(vs Contiguous Memory Allocation)
- 메모리 관리를 받는 사용자 입장에서는 연속된 메모리를 할당받았다고 느끼지만(logical address), 실제 물리 주소 공간에는 프레임 단위로 할당하여 효율적으로 메모리를 할당받을 수 있습니다.
- 페이징으로 인해 외부 단편화를 방지할 수 있습니다.

### Paging의 문제점
페이징은 프로세스의 논리적인 구조와 구성요소들을 전혀 생각하지 않고 크기 단위로 페이지를 나눕니다.  
이런 특징으로 인해 한 프레임 안에 다른 특징의 메모리들이 같이 존재할 수 있습니다.  
이 경우에 프레임 단위로 메모리를 공유하고, protection을 적용하기 때문에 보호와 공유의 기능을 수행하기 어렵습니다.  
이를 보완하고자 Segmentation이라는 기법을 사용합니다.
</details>

<details>
    <summary><b>Segmentation</b></summary>

### Segmentation이란?
Segmentation이란 메모리를 고정 크기의 프레임 단위로 나누는 것이 아니라, 논리적인 내용 단위인 세그먼트로 나누는 방식입니다.  
페이징과 마찬가지로 세그먼트 테이블이 필요하고, 세그먼트는 프레임과 비슷하게 메모리 블럭의 단위 역할을 하지만, 그 크기는 세그먼트마다 다를 수 있습니다.  

### Segmentation의 장단점(vs Paging)
- 장점: 페이징에 비해 보호와 공유의 기능을 하기에 용이합니다. 논리적으로 메모리가 나뉘어있기 때문입니다.
- 단점: 외부 단편화가 발생할 수 있습니다. 이를 해결하기 위해 페이징을 함께 사용하는 하이브리드 방식이 있습니다.
</details>

<details>
    <summary><b>가상 메모리</b></summary>

### 가상 메모리란?
가상 메모리란 프로세스의 필요한 부분만 메모리에 올림으로써 메모리를 효율적으로 사용하는 방식입니다.  
자주 사용되는 내용이나 필요한 내용만 메모리에 올려놓고, 덜 중요한 내용은 하드디스크에 적재하는 방식으로 이루어집니다.  
이 때, 프로그램 실행 중 페이지 메인 메모리에 올라와있지 않은 주소에 참조하게 되면 이때 page fault가 발생하고, 가상 메모리에서 해당 부분을 가져오게 됩니다.

### 가상 메모리의 장단점
- 장점: 메모리를 효율적으로 사용할 수 있기 때문에, 한번에 더 많은 프로세스들을 메모리에 올려놓을 수 있습니다.
- 단점: 페이지 폴트가 발생하면 이 때 I/O 작업에 의해 성능이 떨어질 수 있습니다.

### 가상 메모리 동작 방식
Demand Paging 방식은 프로세스를 페이지로 나누고, 페이지 테이블을 통해 메모리와 가상 메모리를 관리하는 방식입니다.  
page가 메모리에 있는지를 확인하기 위해 page table의 valid-invalid 플래그를 확인합니다.  
만약 invalid라면 페이지 폴트가 발생한 page를 디스크에서 메인 메모리로 올리는 작업을 진행합니다.
</details>

<details>
    <summary><b>페이지 교체 알고리즘. LRU, LFU</b></summary>

### 페이지 교체 알고리즘
페이지 교체 알고리즘은 메인 메모리와 디스크 사이의 페이지를 교체하는 알고리즘으로, 어떤 프레임을 희생되는 프레임으로 할 것인지에 따라 여러 방식이 존재합니다.  
여기에서 페이지 폴트가 적게 발생할 수록 성능이 좋은 알고리즘인데, 페이지 폴트는 페이지와 희생되는 프레임을 교체하는 것 뿐만 아니라, 아직 디스크에 존재하는 페이지를 메모리의 빈 공간에 올리는 것도 포함됩니다.

### 페이지 교체 알고리즘의 종류

1. OPT: 가장 나중에 사용될 것 같은 페이지를 교체하는 알고리즘입니다. 항상 최적의 결과를 보장하지만 미래의 참조를 모두 알고있는 것은 불가능하므로 알고리즘의 upper bound를 제공하는 역할을 합니다.
2. FIFO: 모든 페이지의 우선순위가 평등하다고 가정하고, 가장 먼저 할당된 페이지를 교체하는 알고리즘입니다. 구현하기 간단하지만 알고리즘을 사용하지 않은 경우보다도 페이지 폴트가 더 많이 발생하는 경우가 생깁니다.
3. LRU(Least Recently Used): 가장 오랫동안 사용되지 않은 페이지가 교체되는 알고리즘입니다. 
4. LFU(Least Frequently Used): 가장 적게 사용된 페이지가 교체되는 알고리즘입니다. 최근성을 반영하지 못하지만, 인기도를 더 정확히 반영할 수 있습니다.
</details>
